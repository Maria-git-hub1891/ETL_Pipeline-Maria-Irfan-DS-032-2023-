# ETL_Pipeline_MariaIrfan_DS-032

This project implements a complete **ETL (Extract, Transform, Load)** pipeline using Python. It extracts data from multiple sources (CSV, JSON/API, Google Sheets), processes and cleans the data, and stores the final output in a database-ready format. The notebook `ETL_ASSIGNMENT (2).ipynb` contains the core logic behind the ETL operations.

---

## ğŸ“ Project Structure

ETL_Pipeline_MariaIrfan_DS-032/ â”œâ”€â”€ etl_pipeline.py # ETL main script â”œâ”€â”€ config/ â”‚ â””â”€â”€ db_config.json # Dummy database and API keys â”œâ”€â”€ data/ â”‚ â”œâ”€â”€ sample_data.csv # Example CSV dataset â”‚ â”œâ”€â”€ sample_weather.json # Example JSON/API dataset â”‚ â””â”€â”€ google_sheet_sample.csv # Exported Google Sheets example â”œâ”€â”€ scheduler.py # Scheduler for daily ETL automation â”œâ”€â”€ requirements.txt # Python package dependencies â”œâ”€â”€ README.md # Project documentation â”œâ”€â”€ output/ â”‚ â””â”€â”€ final_cleaned_data.csv # Processed final output â”œâ”€â”€ load_to_db.py # Script to load data into a database â”œâ”€â”€ .github/ â”‚ â””â”€â”€ workflows/ â”‚ â””â”€â”€ ci_cd.yml # GitHub Actions workflow for CI/CD â””â”€â”€ report.pdf


## ğŸš€ ETL Notebook Overview

The notebook `ETL_ASSIGNMENT (2).ipynb` contains:
- âœ… Reading data from different sources:
  - CSV (`sample_data.csv`)
  - JSON (simulated weather API)
  - Google Sheets (exported as CSV)
- âœ… Cleaning and transforming the data
- âœ… Merging and exporting a final dataset
- âœ… Optional loading into a database (via `load_to_db.py`)

ğŸ“ weather-etl-pipeline/
â”œâ”€â”€ weather_etl.py         # Main ETL logic
â”œâ”€â”€ scheduler.py           # Scheduler to run ETL job periodically
â”œâ”€â”€ db_config.json         # MongoDB URI and API key configuration
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ README.md              # Project overview

## ğŸ› ï¸ Setup & Installation

1. Clone the repository:
```bash
git clone https://github.com/your-username/ETL_Pipeline_MariaIrfan_DS-032.git
cd ETL_Pipeline_MariaIrfan_DS-032
Install dependencies:


pip install -r requirements.txt

python -m venv venv
source venv/bin/activate

ğŸ”„ Automation
Use scheduler.py to automate the ETL pipeline daily using:

schedule Python module (in-script scheduler)

Or set up as a cron job for system-level automation

ğŸ§ª CI/CD Integration
The .github/workflows/ci_cd.yml enables GitHub Actions for:

Code linting

Notebook execution tests

Future deployment hooks

ğŸ§° Technologies Used
Python (pandas, json, requests, etc.)

Jupyter Notebook

Git & GitHub

GitHub Actions (CI/CD)

CSV, JSON, Google Sheets

ğŸ“ˆ Output
Final cleaned and merged dataset is printed to console
Data is stored in MongoDB 
Ready for analytics and visualizations


ğŸ“„ License
This project is for academic use only. Please contact the author for other use cases.

ğŸ‘¤ Author
Maria Irfan
Roll Number: DS-032-2023
